import streamlit as st
import pandas as pd
import numpy as np
import joblib
import tensorflow as tf
from tensorflow.keras.models import load_model
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime
import os

# Configuration de la page
st.set_page_config(
    page_title="IDS - D√©tection d'Intrusions avec GRU",
    page_icon="üõ°Ô∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Styles CSS personnalis√©s
st.markdown("""
    <style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .attack-alert {
        background-color: #ff4444;
        padding: 1rem;
        border-radius: 5px;
        color: white;
        font-weight: bold;
    }
    .normal-alert {
        background-color: #00C851;
        padding: 1rem;
        border-radius: 5px;
        color: white;
        font-weight: bold;
    }
    </style>
""", unsafe_allow_html=True)

# Titre principal
st.markdown('<h1 class="main-header">üõ°Ô∏è Syst√®me de D√©tection d\'Intrusions (IDS)</h1>', unsafe_allow_html=True)
st.markdown('<p style="text-align: center; font-size: 1.2rem; color: #666;">D√©tection en temps r√©el avec Deep Learning (GRU Bidirectionnel)</p>', unsafe_allow_html=True)

# Chargement des mod√®les et preprocesseurs
@st.cache_resource
def load_models():
    try:
        model = load_model('models/ids_gru_model.keras')
        scaler = joblib.load('models/scaler_std.pkl')
        encoders = joblib.load('models/label_encoders.pkl')
        dropped_cols = joblib.load('models/dropped_columns.pkl')
        
        # R√©cup√©rer les noms de colonnes attendus par le scaler
        if hasattr(scaler, 'feature_names_in_'):
            expected_features = list(scaler.feature_names_in_)
        else:
            expected_features = None
            
        return model, scaler, encoders, dropped_cols, expected_features
    except Exception as e:
        st.error(f"Erreur lors du chargement des mod√®les: {e}")
        return None, None, None, None, None

model, scaler, encoders, dropped_cols, expected_features = load_models()

# Fonction pour cr√©er des s√©quences
def create_sequences(X, time_steps=10):
    if len(X) < time_steps:
        X = np.tile(X, (time_steps // len(X) + 1, 1))[:time_steps]
    
    Xs = []
    for i in range(len(X) - time_steps + 1):
        Xs.append(X[i:(i + time_steps)])
    return np.array(Xs)

# Fonction de pr√©traitement COMPL√àTE
def preprocess_data(df, scaler, encoders, dropped_cols, expected_features):
    """
    Pr√©traite les donn√©es pour qu'elles correspondent exactement au format d'entra√Ænement
    """
    df_processed = df.copy()
    
    # 1. Normaliser les noms de colonnes (tout en minuscules)
    df_processed.columns = df_processed.columns.str.lower()
    
    # 2. Supprimer l'ID si pr√©sent
    if 'id' in df_processed.columns:
        df_processed = df_processed.drop('id', axis=1)
    
    # 3. Mapper les noms de colonnes du CSV vers ceux du dataset d'entra√Ænement
    column_mapping = {
        'sload': 'sload',
        'dload': 'dload', 
        'spkts': 'spkts',
        'dpkts': 'dpkts',
        'stime': 'stime',
        'ltime': 'ltime',
        'sintpkt': 'sinpkt',
        'dintpkt': 'dinpkt',
        'smeansz': 'smean',
        'dmeansz': 'dmean'
    }
    df_processed = df_processed.rename(columns=column_mapping)
    
    # 4. Calculer les colonnes d√©riv√©es si n√©cessaire
    if 'rate' not in df_processed.columns or df_processed['rate'].isna().all():
        if 'dur' in df_processed.columns and 'spkts' in df_processed.columns:
            df_processed['rate'] = df_processed.apply(
                lambda row: row['spkts'] / row['dur'] if row['dur'] > 0 else 0,
                axis=1
            )
    
    if 'smean' not in df_processed.columns and 'sbytes' in df_processed.columns and 'spkts' in df_processed.columns:
        df_processed['smean'] = df_processed.apply(
            lambda row: int(row['sbytes'] / row['spkts']) if row['spkts'] > 0 else 0,
            axis=1
        )
    
    if 'dmean' not in df_processed.columns and 'dbytes' in df_processed.columns and 'dpkts' in df_processed.columns:
        df_processed['dmean'] = df_processed.apply(
            lambda row: int(row['dbytes'] / row['dpkts']) if row['dpkts'] > 0 else 0,
            axis=1
        )
    
    # 5. Encoder les variables cat√©gorielles AVANT de supprimer les colonnes
    for col in ['proto', 'service', 'state']:
        if col in df_processed.columns and col in encoders:
            le = encoders[col]
            df_processed[col] = df_processed[col].astype(str).apply(
                lambda x: x if x in le.classes_ else le.classes_[0]
            )
            df_processed[col] = le.transform(df_processed[col])
    
    # 6. Supprimer label et attack_cat si pr√©sents
    for col in ['label', 'attack_cat']:
        if col in df_processed.columns:
            df_processed = df_processed.drop(col, axis=1)
    
    # 7. Supprimer les colonnes hautement corr√©l√©es
    for col in dropped_cols:
        if col in df_processed.columns:
            df_processed = df_processed.drop(col, axis=1)
    
    # 8. Si on a les noms de features attendues, s'assurer qu'on les a toutes
    if expected_features is not None:
        # Ajouter les colonnes manquantes avec des valeurs par d√©faut
        for col in expected_features:
            if col not in df_processed.columns:
                df_processed[col] = 0
        
        # R√©organiser les colonnes dans le bon ordre
        df_processed = df_processed[expected_features]
    
    # 9. Normaliser avec le scaler
    X_scaled = scaler.transform(df_processed)
    
    return X_scaled

# Sidebar
with st.sidebar:
    st.image("https://img.icons8.com/clouds/200/000000/security-checked.png", width=150)
    st.markdown("### üìä Options")
    
    demo_mode = st.radio(
        "Mode de d√©monstration:",
        ["üìÅ Charger un fichier CSV", "‚úçÔ∏è Saisie manuelle", "üé≤ Donn√©es al√©atoires"]
    )
    
    st.markdown("---")
    st.markdown("### üìà Statistiques du mod√®le")
    st.metric("Pr√©cision", "97%")
    st.metric("Recall", "97%")
    st.metric("F1-Score", "97%")
    
    st.markdown("---")
    
    # Afficher les informations sur les features si disponibles
    if expected_features is not None:
        with st.expander("‚ÑπÔ∏è Features du mod√®le"):
            st.write(f"**Nombre de features:** {len(expected_features)}")
            st.write(f"**Colonnes supprim√©es:** {len(dropped_cols)}")
    
    st.markdown("---")
    st.info("Mod√®le: GRU Bidirectionnel\nDataset: UNSW-NB15\nD√©velopp√© par: DJILI & El Kadiri")

# Corps principal
if model is None:
    st.error("‚ö†Ô∏è Impossible de charger le mod√®le. V√©rifiez que tous les fichiers sont pr√©sents dans le dossier 'models/'.")
elif expected_features is None:
    st.warning("‚ö†Ô∏è Impossible de r√©cup√©rer les noms des features. Le scaler ne contient pas 'feature_names_in_'.")
else:
    # Mode 1: Upload de fichier CSV
    if demo_mode == "üìÅ Charger un fichier CSV":
        st.markdown("### üìÇ Chargement de donn√©es")
        
        uploaded_file = st.file_uploader("Choisissez un fichier CSV", type=['csv'])
        
        if uploaded_file is not None:
            try:
                df = pd.read_csv(uploaded_file)
                
                st.success(f"‚úÖ Fichier charg√© avec succ√®s! {len(df)} enregistrements d√©tect√©s.")
                
                col1, col2 = st.columns(2)
                with col1:
                    st.markdown("#### Aper√ßu des donn√©es")
                    st.dataframe(df.head(10), use_container_width=True)
                
                with col2:
                    st.markdown("#### Informations")
                    st.write(f"**Nombre de lignes:** {len(df)}")
                    st.write(f"**Nombre de colonnes:** {len(df.columns)}")
                
                if st.button("üîç Analyser le trafic", type="primary", use_container_width=True):
                    with st.spinner("Analyse en cours..."):
                        try:
                            # Pr√©traitement
                            X_processed = preprocess_data(df, scaler, encoders, dropped_cols, expected_features)
                            
                            # Cr√©ation des s√©quences
                            X_seq = create_sequences(X_processed, time_steps=10)
                            
                            # Pr√©dictions
                            predictions = model.predict(X_seq, verbose=0)
                            predictions_binary = (predictions > 0.5).astype(int).flatten()
                            
                            # R√©sultats
                            n_attacks = np.sum(predictions_binary)
                            n_normal = len(predictions_binary) - n_attacks
                            attack_percentage = (n_attacks / len(predictions_binary)) * 100
                            
                            st.markdown("---")
                            st.markdown("### üìä R√©sultats de l'analyse")
                            
                            # M√©triques
                            col1, col2, col3, col4 = st.columns(4)
                            
                            with col1:
                                st.metric("Total analys√©", len(predictions_binary))
                            
                            with col2:
                                st.metric("Trafic Normal", n_normal, delta=f"{100-attack_percentage:.1f}%")
                            
                            with col3:
                                st.metric("Attaques d√©tect√©es", n_attacks, delta=f"{attack_percentage:.1f}%", delta_color="inverse")
                            
                            with col4:
                                if attack_percentage > 50:
                                    st.metric("Niveau de menace", "√âLEV√â ‚ö†Ô∏è")
                                elif attack_percentage > 20:
                                    st.metric("Niveau de menace", "MOYEN ‚ö°")
                                else:
                                    st.metric("Niveau de menace", "FAIBLE ‚úÖ")
                            
                            # Graphiques
                            col1, col2 = st.columns(2)
                            
                            with col1:
                                fig_pie = go.Figure(data=[go.Pie(
                                    labels=['Normal', 'Attaque'],
                                    values=[n_normal, n_attacks],
                                    hole=.3,
                                    marker_colors=['#00C851', '#ff4444']
                                )])
                                fig_pie.update_layout(title="Distribution du trafic", height=400)
                                st.plotly_chart(fig_pie, use_container_width=True)
                            
                            with col2:
                                fig_hist = go.Figure(data=[go.Histogram(
                                    x=predictions.flatten(),
                                    nbinsx=50,
                                    marker_color='#667eea'
                                )])
                                fig_hist.update_layout(
                                    title="Distribution des probabilit√©s d'attaque",
                                    xaxis_title="Probabilit√©",
                                    yaxis_title="Fr√©quence",
                                    height=400
                                )
                                st.plotly_chart(fig_hist, use_container_width=True)
                            
                            # Tableau d√©taill√©
                            st.markdown("### üìã D√©tails des pr√©dictions")
                            results_df = pd.DataFrame({
                                'Index': range(len(predictions_binary)),
                                'Probabilit√©': predictions.flatten(),
                                'Pr√©diction': ['Attaque' if p == 1 else 'Normal' for p in predictions_binary],
                                'Confiance': [f"{p*100:.1f}%" if predictions_binary[i] == 1 else f"{(1-p)*100:.1f}%" 
                                             for i, p in enumerate(predictions.flatten())]
                            })
                            
                            filter_option = st.selectbox("Filtrer par:", ["Tous", "Attaques uniquement", "Normal uniquement"])
                            
                            if filter_option == "Attaques uniquement":
                                results_df = results_df[results_df['Pr√©diction'] == 'Attaque']
                            elif filter_option == "Normal uniquement":
                                results_df = results_df[results_df['Pr√©diction'] == 'Normal']
                            
                            st.dataframe(
                                results_df.style.applymap(
                                    lambda x: 'background-color: #ffcccc' if x == 'Attaque' else 
                                             ('background-color: #ccffcc' if x == 'Normal' else ''),
                                    subset=['Pr√©diction']
                                ),
                                use_container_width=True,
                                height=400
                            )
                            
                            # T√©l√©chargement
                            csv = results_df.to_csv(index=False).encode('utf-8')
                            st.download_button(
                                label="üì• T√©l√©charger les r√©sultats (CSV)",
                                data=csv,
                                file_name=f"ids_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                                mime="text/csv"
                            )
                        except Exception as e:
                            st.error(f"‚ùå Erreur lors de l'analyse: {e}")
                            with st.expander("üîç D√©tails de l'erreur (pour debug)"):
                                import traceback
                                st.code(traceback.format_exc())
                        
            except Exception as e:
                st.error(f"‚ùå Erreur lors du chargement: {e}")
    
    # Mode 2: Saisie manuelle
    elif demo_mode == "‚úçÔ∏è Saisie manuelle":
        st.markdown("### ‚úçÔ∏è Saisie manuelle des param√®tres r√©seau")
        st.info("Entrez les caract√©ristiques d'un paquet r√©seau pour analyse")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            proto = st.selectbox("Protocole", ['tcp', 'udp', 'icmp', 'arp', 'idrp'])
            state = st.selectbox("√âtat", ['FIN', 'INT', 'CON', 'REQ', 'RST'])
            service = st.selectbox("Service", ['-', 'dns', 'http', 'ftp', 'ssh'])
        
        with col2:
            dur = st.number_input("Dur√©e (s)", 0.0, 1000.0, 0.000007, format="%.6f")
            spkts = st.number_input("Paquets Source", 0, 10000, 2)
            dpkts = st.number_input("Paquets Destination", 0, 10000, 0)
        
        with col3:
            sttl = st.number_input("TTL Source", 0, 255, 60)
            dttl = st.number_input("TTL Destination", 0, 255, 0)
            sload = st.number_input("Charge Source", 0.0, 1e9, 150857136.0, format="%.1f")
        
        if st.button("üîç Analyser ce paquet", type="primary", use_container_width=True):
            # Cr√©er un DataFrame minimal
            manual_data = pd.DataFrame([{
                'proto': proto, 'service': service, 'state': state,
                'dur': dur, 'spkts': spkts, 'dpkts': dpkts,
                'sttl': sttl, 'dttl': dttl, 'sload': sload,
                'dload': 0.0, 'sloss': 0, 'dloss': 0,
                'swin': 0, 'dwin': 0, 'stcpb': 0, 'dtcpb': 0,
                'trans_depth': 0, 'response_body_len': 0,
                'sjit': 0.0, 'djit': 0.0, 
                'sinpkt': 0.007, 'dinpkt': 0.0, 
                'tcprtt': 0.0, 'synack': 0.0, 'ackdat': 0.0,
                'is_sm_ips_ports': 0, 'ct_state_ttl': 0, 
                'ct_flw_http_mthd': 0, 'is_ftp_login': 0, 
                'ct_ftp_cmd': 0, 'ct_srv_src': 29, 'ct_srv_dst': 29,
                'ct_dst_ltm': 9, 'ct_src_ltm': 9, 
                'ct_src_dport_ltm': 9, 'ct_dst_sport_ltm': 9, 
                'ct_dst_src_ltm': 29
            }])
            
            try:
                with st.spinner("Analyse en cours..."):
                    X_processed = preprocess_data(manual_data, scaler, encoders, dropped_cols, expected_features)
                    X_seq = create_sequences(X_processed, time_steps=10)
                    prediction = model.predict(X_seq, verbose=0)[0][0]
                    is_attack = prediction > 0.5
                    
                    st.markdown("---")
                    st.markdown("### üéØ R√©sultat de l'analyse")
                    
                    if is_attack:
                        st.markdown(f'<div class="attack-alert">‚ö†Ô∏è ATTAQUE D√âTECT√âE - Confiance: {prediction*100:.2f}%</div>', unsafe_allow_html=True)
                    else:
                        st.markdown(f'<div class="normal-alert">‚úÖ TRAFIC NORMAL - Confiance: {(1-prediction)*100:.2f}%</div>', unsafe_allow_html=True)
                    
                    # Jauge
                    fig_gauge = go.Figure(go.Indicator(
                        mode="gauge+number+delta",
                        value=prediction * 100,
                        domain={'x': [0, 1], 'y': [0, 1]},
                        title={'text': "Probabilit√© d'attaque (%)"},
                        delta={'reference': 50},
                        gauge={
                            'axis': {'range': [None, 100]},
                            'bar': {'color': "darkred" if is_attack else "darkgreen"},
                            'steps': [
                                {'range': [0, 50], 'color': "lightgreen"},
                                {'range': [50, 100], 'color': "lightcoral"}
                            ],
                            'threshold': {
                                'line': {'color': "red", 'width': 4},
                                'thickness': 0.75,
                                'value': 50
                            }
                        }
                    ))
                    st.plotly_chart(fig_gauge, use_container_width=True)
                    
            except Exception as e:
                st.error(f"‚ùå Erreur: {e}")
                with st.expander("üîç D√©tails"):
                    import traceback
                    st.code(traceback.format_exc())
    
    # Mode 3: Donn√©es al√©atoires
    else:
        st.markdown("### üé≤ G√©n√©ration de donn√©es al√©atoires")
        
        n_samples = st.slider("Nombre d'√©chantillons:", 10, 500, 100)
        
        if st.button("üé≤ G√©n√©rer et analyser", type="primary", use_container_width=True):
            try:
                if os.path.exists('data_sample/unsw_nb15_demo_binary_2000.csv'):
                    sample_df = pd.read_csv('data_sample/unsw_nb15_demo_binary_2000.csv')
                    random_df = sample_df.sample(n=min(n_samples, len(sample_df)))
                else:
                    st.error("Fichier de donn√©es d'exemple introuvable!")
                    st.stop()
                
                with st.spinner("Analyse en cours..."):
                    X_processed = preprocess_data(random_df, scaler, encoders, dropped_cols, expected_features)
                    X_seq = create_sequences(X_processed, time_steps=10)
                    predictions = model.predict(X_seq, verbose=0)
                    predictions_binary = (predictions > 0.5).astype(int).flatten()
                    
                    n_attacks = np.sum(predictions_binary)
                    n_normal = len(predictions_binary) - n_attacks
                    attack_percentage = (n_attacks / len(predictions_binary)) * 100
                    
                    st.markdown("---")
                    st.markdown("### üìä R√©sultats")
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("Analys√©s", len(predictions_binary))
                    with col2:
                        st.metric("Normal", n_normal, delta=f"{100-attack_percentage:.1f}%")
                    with col3:
                        st.metric("Attaques", n_attacks, delta=f"{attack_percentage:.1f}%", delta_color="inverse")
                    
                    # Graphique temporel
                    fig_timeline = go.Figure()
                    fig_timeline.add_trace(go.Scatter(
                        y=predictions.flatten(),
                        mode='lines+markers',
                        name='Probabilit√©',
                        line=dict(color='#667eea', width=2),
                        marker=dict(
                            size=6,
                            color=predictions_binary,
                            colorscale=[[0, '#00C851'], [1, '#ff4444']],
                            showscale=True
                        )
                    ))
                    fig_timeline.add_hline(y=0.5, line_dash="dash", line_color="red", annotation_text="Seuil")
                    fig_timeline.update_layout(
                        title="√âvolution temporelle",
                        xaxis_title="Index",
                        yaxis_title="Probabilit√©",
                        height=400
                    )
                    st.plotly_chart(fig_timeline, use_container_width=True)
                    
            except Exception as e:
                st.error(f"‚ùå Erreur: {e}")
                with st.expander("üîç D√©tails"):
                    import traceback
                    st.code(traceback.format_exc())

# Footer
st.markdown("---")
st.markdown("""
    <div style='text-align: center; color: #666; padding: 2rem;'>
        <p>üõ°Ô∏è Syst√®me de D√©tection d'Intrusions - Projet ML/DL pour Cybers√©curit√©</p>
        <p>D√©velopp√© par DJILI Mohamed Amine & El Kadiri Omar</p>
    </div>
""", unsafe_allow_html=True)
